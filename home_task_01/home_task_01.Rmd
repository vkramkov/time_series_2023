---
title: 'R Notebook Home Task 01: Random process simulations and description'
output: html_notebook
---

Это R Notebook. Он состоит из форматированного текста и исполняемого кода. Результат кода показывается под соответствующим фрагментом кода.

Если вы открыли .Rmd в R, то можете исполнять код по кнопке *Run* около фрагмента кода, либо комбинацей *Ctrl+Shift+Enter*, предварительно поместив курсор внутри кода.

Если вы открыли HTML документ, то исполнить код не получится - вместо него показывается результат исполнения кода в момент формирования HTML документа.

Для начала необходимо загрузить несколько библиотек. Если они отсутствуют, нужно их установить через Tools / Install Packages..., введя названия библиотек в нужное поле. После установки - вернуться к этому фрагменту кода

```{r}
library(tidyverse)
library(stargazer)
```

Если все получилось, перейдем к основной части.

# home_task_01: Генерация и описание случайных процессов

В этом задании мы научимся работать со случайными процессами: будем генерировать реализации случайных процессов, отображать их на графиках и изучать их свойства. Мы выясним, на что нужно обратить внимание во временном ряде, чтобы понять, как он устроен. Когда в следующих заданиях мы столкнемся с реальными временными рядами, относительно которых мы не знаем истинный процесс, создавший эти данные, мы будем готовы этот неизвестный процесс проанализировать.

Разбираться будем на примере трех стационарных процессов - белый шум, скользящего среднего, авторегрессии (далее WN, MA и AR).

Для воспроизводимости результатов зафиксируем состояние генератора случайных величин.

```{r}
set.seed(20230905)
```

Приступим.

## Процесс белого шума (WN)

Вспомним, что процесс белого шума - это последовательность независимых и одинакового распределенных случайных величин (распределение при этом может быть любым - например, нормальным).

$y_t = \varepsilon_t, \varepsilon_t \sim iidN(0,\sigma^2 )$

Поэтому сгенерировать реализацию процесса белого шума можно с помощью генератора случайных чисел.

```{r}
# Сгенерируем временной ряд как реализацию нормального белого шума
ts_length <- 1000
wn_ts <- rnorm(n = ts_length, mean = 5, sd = 2)
wn_table <- tibble(
  time = 1:ts_length,
  white_noise = wn_ts)
rm(ts_length)
```

Длина получившегося временного ряда равна 1000, среднее = 5 и стандартное отклонение = 2 (дисперсия, следовательно, 4). Сгенерированный ряд мы поместили в вектор `wn_ts` и в таблицу `wn_table`.

Итак, мы создали временной ряд по модели нормального белого шума со средним 5 и стандартным отклонением 2. Но при анализе реальных временных рядов мы не будем знать, по какой модели создан временной ряд. Поэтому временно забудем настоящую модель и попробуем восстановить ее параметры самостоятельно.

Построим график этого временного ряда.

```{r}
wn_plot <- ggplot(wn_table, aes(x = time, y = white_noise)) +
  geom_line() + 
  xlab("") + 
  theme_bw()
wn_plot
```

Перед основным анализом убедимся, что мы можем предположить стационарность нашего ряда. Действительно, наш ряд имеет примерно постоянное среднее и характеризуется примерно постоянным разбросом вокруг среднего. Отдельные участки графика по форме не отличаются от соседних. Следовательно, мы можем предположить, что наш ряд создан каким-то стационарным процессом. Позднее мы узнаем, что эту гипотезу можно проверить и формально, с помощью тестов на стационарность, но сейчас ограничимся своим экспертным суждением.

Теперь рассчитаем и визуализируем описательные статистики нашего ряда. Начнем со среднего и дисперсии.

```{r}
wn_stats <- wn_table |> summarise(mean = mean(white_noise),
                            median = median(white_noise),
                            sd = sd(white_noise),
                            mad = mad(white_noise))
wn_stats
```

Видим, что временной ряд имеет среднее 5.02 и стандартное отклонение 2.02. Их робастные к выбросам аналоги - медиана и медианное отклонение - близки к тем же значениям. Вспомним, что настоящие параметры равны 5 и 2 соответственно, так что наши оценки достаточно близки к истинным параметрам, но все же только оценки.

Теперь попробуем оценить плотность распределения. Ясно, что мы можем использовать плотность, потому что множество значений нашего ряда явно непрерывно. Если бы у нашего ряда было небольшое число возможных значений, то это был бы дискретный временной ряд (не путать с непрерывным/дискретным временем) и плотность оценивать не стоило бы.

Для оценок плотности ранее использовались гистограммы, а в настоящее время чаще прибегают к ядерным оценкам. Не вдаваясь в их формулы, посмотрим на итоговый результат.

```{r}
plot_wn_density <- ggplot(wn_table, aes(x = white_noise)) +
  geom_histogram(aes(y = after_stat(density)), colour = "black", fill = "white", bins = 30) +
  geom_density(alpha = 0.2, fill = "blue") + 
  geom_vline(aes(xintercept = mean(white_noise)),
            color = "blue", size = 1) +
  theme_bw() +
  xlab("") + ylab("")
plot_wn_density
```

Оцененная плотность распределения (а также гистограмма) по форме напоминают нормальное распределение. Пока удовлетворимся этим, а в будущем будем иметь в виду возможность использовать специальные тесты для проверки нормальности распределения.

Отразим на графике оценки среднего и стандартных отклонений.

```{r}
wn_plot + 
  geom_hline(aes(yintercept = wn_stats$mean),
             color = "blue", size = 1) +
  geom_hline(aes(yintercept = wn_stats$mean - wn_stats$sd), 
             color = "blue", linetype = "dashed", size = 1) +
    geom_hline(aes(yintercept = wn_stats$mean + wn_stats$sd), 
             color = "blue", linetype = "dashed", size = 1)
```

Итак, мы провели визуальный анализ временного ряда, сделали вывод о его стационарности, рассмотрели и оценили среднее временного ряда и его стандартное отклонение. Для того, чтобы завершить описание ряда и окончательно его классифицировать, мы должны рассмотреть соотношение между соседними значениями временного ряда.

Например, можно посчитать автокорреляционную функцию, то есть оценить корреляцию между значениями временного ряда, отстоящие на фиксированное число периодов. График, изображающий такую функцию, называется кореллограммой.

```{r}
wn_ts |> acf(lag.max = 20, main = 'Автокорреляционная функция')
```

Значение автокорреляционной функции в точке 0 всегда равно 1 (корреляция случайной величины с самой собой равна 1). В других точках показывается корреляция случайных величин, разница между которыми по времени соответствует эти точкам. На графике одновременно показывается интервал незначимой корреляции. В нашем случае мы видим, что автокорреляционная функция нигде не значима и находится вблизи нуля. Это свидетельствует о том. что соседние значения временного ряда скорее всего независимы.

Часто используется понятие частной автокорреляционной функции. Это более сложное понятие, которое показывает частную автокорреляцию, то есть корреляцию двух соседних величин при фиксированных величинах между ними.

```{r}
wn_ts |> acf(lag.max = 20, type = 'partial', main = 'Автокорреляционная функция')
```

Для белого шума разница между ними не столь очевидна, вернемся к ним позже.

Кроме того, можно показать сходство двух соседних значений временных рядов с помощью обычной диаграммы рассеяния.

```{r}
wn_table <- wn_table |> 
  mutate(wn_lag_1 = lag(white_noise, 1),
         wn_lag_2 = lag(white_noise, 2))
ggplot(wn_table |> drop_na(), aes(x = wn_lag_1, y = white_noise)) +
  geom_point(alpha = 0.4, size = 2) + 
  geom_smooth(method = 'lm', se = F) +
  theme_classic() + 
  xlab("") + ylab("")
```

Точки на диаграмме рассеяния не демонстрируют какой-либо тенденции, а добавленная к графику линия регрессии (в данном случае - авторегрессии) лишь подтверждает отсутствие зависимости между соседними величинами. Аналогичная картина наблюдается и для любых других лагов.

```{r}
ggplot(wn_table |> drop_na(), aes(x = wn_lag_2, y = white_noise)) +
  geom_point(alpha = 0.4, size = 2) + 
  geom_smooth(method = 'lm', se = F) +
  theme_classic() + 
  xlab("") + ylab("")
```

Для отдельных случаев может быть полезно добавить к диаграмме рассеяния вместо линейной регрессии квантильные регрессии. Они более устойчивы к выбросам, а еще проверят наличие авторегрессионной гетероскедастичности.

```{r}
ggplot(wn_table |> drop_na(), aes(x = wn_lag_1, y = white_noise)) +
  geom_point(alpha = 0.4, size = 2) + 
  geom_quantile() +
  theme_classic() + 
  xlab("") + ylab("")
```

В данном случае авторегрессионная гетероскедастичность отсутствует. Для тех же целей можно показать оценку двумерной плотности:

```{r}
ggplot(wn_table |> drop_na(), aes(x = wn_lag_1, y = white_noise)) +
  geom_point(alpha = 0.4, size = 2) + 
  geom_density_2d() +
  theme_classic() + 
  xlab("") + ylab("")
```

График, близкий к концентрическим окружностям (или эллипсам, вытянутым горизонтально/вертикально, но не диагонально), показывает не только отсутствие авторегрессии и авторегрессионной гетероскедастичности, но и близость к нормальному распределению.

Итак, пора делать вывод.

### Вывод:

*Наш временной ряд можно классифицировать как стационарный: он обладает постоянным средним (матожидание = 5) и постоянным разбросом (стандартное отклонение = 2). Его распределение можно считать нормальным. Автокорреляция отсутствует. Признаков авторегрессии и авторегрессионной гетероскедастичности нет. По этим признакам ряд можно моделировать с помощью случайного процесса нормального белого шума со средним вблизи 5 и стандартным отклонением вблизи 2.*

Теперь вспомним, что мы действительно создали временной ряд как реализацию процесса белого шума со средним 5 и стандартным отклонением 2. Значит, нам удалось верно определить основные свойства ряда и восстановить процесс, создавший ряд.

## Процесс авторегрессии

Теперь рассмотрим процесс авторегрессии 1 первого порядка. В математической записи этого процесса в правой части уравнения присутствует один лаг (по умолчанию первый) зависимой переменной.

$y_t = \phi_0 + \phi_1  y_{t-1} + \varepsilon_t, \varepsilon_t \sim iid(0,\sigma^2 )$

Сгенерируем реализацию из этого процесса, предполагая нормальное распределение для шума. Для этого сначала с помощью генератора случайных чисел создадим временной ряд шума, затем на его основе сгенерируем временной ряд самого процесса.

```{r}
# Сгенерируем временной ряд как реализацию нормального белого шума
ts_length <- 1200
burn_length <- 200
ar_ts <- rnorm(n = ts_length, mean = 5, sd = 2)
for (i in 2:ts_length) {
  ar_ts[i] <- 0.9 * ar_ts[i - 1] + ar_ts[i]
}
ar_table <- tibble(
  time = 1:(ts_length - burn_length),
  ar = ar_ts[(burn_length+1):ts_length])
rm(ts_length, burn_length, i)
```

Мы создали временной ряд с длиной 1000 наблюдений, $\phi_0 = 2$, $\phi_1 = 0.9$ и$\sigma^2 = 1$. Обратим внимание на распространенный прием: мы позволили нашей модели "разогреться" в течение первых 200 генераций и не взяли в итог наблюдения в этот период разминки. Это распространенный прием при генерации случайных величин достаточно сложных распределений.

Как и прежде, временно забудем истинную модель и восстановим ее параметры собственным анализом. Для этого визуализируем временной ряд.

```{r}
ar_plot <- ggplot(ar_table, aes(x = time, y = ar)) +
  geom_line() + 
  xlab("") + 
  theme_bw()
ar_plot
```

Как и ранее, начнем с проверки стационарности. График, конечно, отличается от графика белого шума: присутствуют затяжные отклонения от среднего. И все же основные свойства стационарного ряда налицо: как минимум, среднее и дисперсия примерно постоянны. Не прибегая пока к формальной проверке гипотезы о стационарности, далее будем исходить из ее справедливости.

Рассчитаем характеристики:

```{r}
ar_stats <- ar_table |> summarise(mean = mean(ar),                  median = median(ar), sd = sd(ar), mad = mad(ar)) 
ar_stats
```

Наш ряд имеет среднее вблизи 50 и стандартное отклонение вблизи 4.5. Робастные метрики подтверждают результаты основных метрик.

**Вопрос:** *Откуда возникли 50 и 4.5? В генераторе случайных величин стояли 5 и 2!*

Отразим на графике оценки среднего и стандартных отклонений.

```{r}
ar_plot + 
  geom_hline(aes(yintercept = ar_stats$mean),
             color = "blue", size = 1) +   
  geom_hline(aes(yintercept = ar_stats$mean - ar_stats$sd),               color = "blue", linetype = "dashed", size = 1) +
  geom_hline(aes(yintercept = ar_stats$mean + ar_stats$sd),               color = "blue", linetype = "dashed", size = 1)
```

Перейдем к автокорреляционным фунциям - обычной и частной.

```{r}
ar_table |> pull(ar) |> acf(lag.max = 20, main = 'Автокорреляционная функция')
```

Мы видим очевидные признаки зависимости близких значений временного ряда. Так, корреляция между соседними значениями значительна и составляет примерно 0.9. Между значениями, отстоящими на два периода, корреляция меньше, но все равно высока - 0.8. По мере удаления значений корреляция плавно снижается, но остается значимой вплоть до 15 лага.

```{r}
ar_table |> pull(ar) |> acf(lag.max = 20, main = 'Частная автокорреляционная функция', type = 'partial')
```

В то же время на графике частной автокорреляционной функции присутствует только первый лаг (со значением вблизи 0.9). На этом основании мы можем заключить, что сходство между периодом "сегодня" и периодом "позавчера" возникает только посредством периода "вчера". При фиксированном значении "вчера" гипотетическое изменение значении "позавчера" не влияет на значение "сегодня". А еще это значит, что модель авторегрессии должна быть первого порядка.

Что с диаграммой рассеяния?

```{r}
ar_table <- ar_table |> 
  mutate(ar_lag_1 = lag(ar, 1),
         ar_lag_2 = lag(ar, 2),
         ar_lag_8 = lag(ar, 8))
ggplot(ar_table |> drop_na(), aes(x = ar_lag_1, y = ar)) +
  geom_point(alpha = 0.4, size = 2) + 
  geom_smooth(method = 'lm', se = F) +
  theme_classic() + 
  xlab("") + ylab("")
```

Уравнение авторегрессии можно вывести отдельно.

```{r}
model <- lm(ar~ar_lag_1, data = ar_table)
stargazer(model, type = "text")
```

Очевидна и ярко выражена зависимость двух соседних значений. А для отстоящих на несколько периодов?

```{r}
ggplot(ar_table |> drop_na(), aes(x = ar_lag_8, y = ar)) +
  geom_point(alpha = 0.4, size = 2) + 
  geom_smooth(method = 'lm', se = F) +
  theme_classic() + 
  xlab("") + ylab("")
```

Зависимость удаленных на 8 периодов значений не столь выражена, но тоже присутствует в нашем временном ряде.

Иногда коэффициенты авторегрессии представляют с помощью периода полураспада (*half-life*), или, что точнее, продолжительности полувозврата к среднему - времени, за которое случайно возникшее отклонение от среднего сокращается вдвое.

```{r}
-log(2)/log(coef(model)[2])
```

Рассматриваемый нами процесс закрывает половину отклонения от среднего в среднем за 6-7 периодов.

На всякий случай проверим наличие авторегрессионной гетероскедастичности и отклонения от нормального распределения:

```{r}
ggplot(ar_table |> drop_na(), aes(x = ar_lag_2, y = ar)) +
  geom_point(alpha = 0.4, size = 2) + 
  geom_quantile(size = 1, col = 'black') +
  geom_density2d() +
  theme_classic() + 
  xlab("") + ylab("")
```

Квантильные линии параллельны, контурные линии образуют концентрические эллипсы - признаков авторегрессионной гетероскедастичности и/или отклонений от нормальности нет.

### Вывод:

Ряд стационарный, но точно не процесс белого шума. Имеется тесная линейная связь между значениями близких периодов. Корреляция между ними плавно убывает с удалением периодов, но значимая частная автокорреляция наблюдается только для 1 лага. Временной ряд может быть смоделирован с помощью процесса авторегрессии 1 порядка с коэффициентом вблизи 0.9 и константой вблизи 5.3.

## Процесс скользящего среднего

Теперь рассмотрим процесс скользящего среднего второго порядка. В математической записи этого процесса в правой части уравнения присутствуют два лага (по умолчанию первые два) шума.

$y_t = \mu +\varepsilon_t + \phi_1  \varepsilon_{t-1} + \phi_2  \varepsilon_{t-2}, \varepsilon_t \sim iid(0,\sigma^2 )$

Сгенерируем реализацию из этого процесса, предполагая на этот раз равномерное распределение для шума. Для этого сначала с помощью генератора случайных чисел создадим временной ряд шума, затем на его основе сгенерируем временной ряд самого процесса.

```{r}
# Сгенерируем временной ряд как реализацию нормального белого шума
ts_length <- 1000 
ma_table <- tibble(   
  time = 1:ts_length,   
  noise = runif(n = ts_length, min = -2, max = 6)) |> 
  mutate(ma = noise + 0.95 * lag(noise, 1) + 0.55 * lag(noise, 2) + 10) |> drop_na()
rm(ts_length)
```

Мы создали временной ряд с длиной 1000 наблюдений, $\phi_1 = 0.95$, $\phi_2 = 0.55$.

# Домашнее задание

1.  Проанализировать процесс скользящего среднего по аналогии с процессами белого шума и авторегрессии. Сделать выводы, подтвердить графиками и расчетами. В чем проявляется ненормальность распределения шума?

2.  Модифицировать коэффициенты процесса авторегрессии/скользящего среднего, увеличить их порядок. Провести анализ. Дополнительно: изменить тип распределения (но с сохранением стационарности).

3.  Понять, как влияют коэффициенты и порядок процессов AR и MA на их обычные и частные автокорреляционные функции. Для этого, изменяя коэффициенты и порядки процессов, наблюдать их ACF и PACF, фиксируя закономерности. Дополнительно: рассмотреть процесс, являющийся суммой двух процессов (AR и AR, AR и MA).
